{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8XQ1zLg4t0u"
      },
      "source": [
        "**Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "bDXJCDJp3khL",
        "outputId": "82c9fdf0-4683-4382-98b0-1fb083b97868"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv('new.csv', names=[\"Timestamp\", \"Duration\", \"Type\", \"Level\",\n",
        "                                      \"Client\", \"Client ID\", \"Query ID\",\n",
        "                                      \"Query Name\", \"View\", \"Recursion\",\n",
        "                                      \"Query Type\", \"Query\", \"Class\",\n",
        "                                      \"Record Type\", \"Flags\", \"IP Address\"],low_memory=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eQnDbtT44cU"
      },
      "source": [
        "**Check dataset property**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_2BgJ9w40xN",
        "outputId": "93e8d1b4-6b18-4797-db5d-ed55fe509439"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of rows: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "null_values = df.isnull().sum()\n",
        "print(\"Null values :\\n\",null_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKyfbKhw5Piv",
        "outputId": "c1b3a8c3-eee2-433d-a16e-a13d74d7f58e"
      },
      "outputs": [],
      "source": [
        "# Displaying rows with any null values\n",
        "rows_with_nulls = df[df.isnull().any(axis=1)]\n",
        "print(rows_with_nulls.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gpEJwlk5m0u"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iAadUZe5fLZ",
        "outputId": "b59589de-da1c-4b21-aa05-901fcbe01bbb"
      },
      "outputs": [],
      "source": [
        "# Dropping null values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Verify that the rows with null values have been dropped\n",
        "print(df.isnull().sum())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-mUUAEI5xj8"
      },
      "source": [
        "**Feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znc1301L50vw",
        "outputId": "7562bb9b-0df1-4d42-b269-93c7c972690f"
      },
      "outputs": [],
      "source": [
        "# List of columns to select\n",
        "columns_to_select = [\"Timestamp\", \"Duration\", \"Client\", \"Client ID\", \"Query ID\", \"Query\", \"Class\", \"Record Type\", \"Flags\", \"IP Address\"]\n",
        "\n",
        "# Select the specified columns\n",
        "selected_df = df[columns_to_select]\n",
        "\n",
        "# Display the first few rows of the selected DataFrame\n",
        "print(selected_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL5yWgA458ik"
      },
      "source": [
        "**Transforming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDHMublx5_uf",
        "outputId": "af63f64f-e18a-48c8-8908-0ba8cd8645fd"
      },
      "outputs": [],
      "source": [
        "# Convert the \"Timestamp\" column to datetime with error handling\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
        "\n",
        "# Verify the conversion\n",
        "print(df['Timestamp'].head())\n",
        "print(df['Timestamp'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaSr7gSd6Flg",
        "outputId": "1e303e79-a15e-489d-96a7-9153ed5b6a59"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIEYJtRH6Pmt"
      },
      "source": [
        "**Date time stamp**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHbAAQwU6Geq",
        "outputId": "c84e90d4-5628-4db0-cae0-14fb165eba4d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the function to format time\n",
        "def format_time(time_str):\n",
        "  try:\n",
        "      # Split the time string into minutes, seconds, and tenths of a second\n",
        "      minutes, rest = time_str.split(':')\n",
        "      seconds, tenths = rest.split('.')\n",
        "\n",
        "      # Convert to integers\n",
        "      minutes = int(minutes)\n",
        "      seconds = int(seconds)\n",
        "      milliseconds = int(tenths) * 100  # Convert tenths of a second to milliseconds\n",
        "\n",
        "      # Calculate total milliseconds\n",
        "      total_milliseconds = (minutes * 60 * 1000) + (seconds * 1000) + milliseconds\n",
        "\n",
        "      # Convert to timedelta\n",
        "      time_delta = pd.to_timedelta(total_milliseconds, unit='ms')\n",
        "\n",
        "      # Format the time\n",
        "      formatted_time = f\"{time_delta.components.hours:02}:{time_delta.components.minutes:02}:{time_delta.components.seconds:02}.{time_delta.components.milliseconds:03}\"\n",
        "      return formatted_time\n",
        "  except Exception as e:\n",
        "      print(f\"Error formatting time: {time_str} - {e}\")\n",
        "      return None  # Return None for invalid entries\n",
        "\n",
        "# Create a copy of the DataFrame\n",
        "selected_columns = selected_df.copy()\n",
        "\n",
        "# Apply the function to each row\n",
        "selected_columns['time'] = selected_columns['Duration'].apply(format_time)\n",
        "\n",
        "# Convert the 'time' column to timedelta type\n",
        "selected_columns['time'] = pd.to_timedelta(selected_columns['time'])\n",
        "\n",
        "# Format the 'time' column to remove \"0 days\"\n",
        "selected_columns['time'] = selected_columns['time'].apply(lambda x: f\"{x.components.hours:02}:{x.components.minutes:02}:{x.components.seconds:02}.{x.components.milliseconds:03}\")\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(selected_columns.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unQ-y7Zw6cHz"
      },
      "source": [
        "**Selecting and dropping feature column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulEv4B0V6WOG",
        "outputId": "1e124f57-11ad-48da-bc1d-28fb70250bb6"
      },
      "outputs": [],
      "source": [
        "selected_columns = selected_columns.drop('Duration', axis=1)\n",
        "print(selected_columns.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_uMq1-O6wGo",
        "outputId": "99cf2a28-e344-42fa-e98f-2e45fba45fa1"
      },
      "outputs": [],
      "source": [
        "# Combine 'Timestamp' and 'time' columns into a single datetime column\n",
        "selected_columns['Timestamp'] = pd.to_datetime(selected_columns['Timestamp']) + pd.to_timedelta(selected_columns['time'])\n",
        "\n",
        "# Drop the 'time' column as it's now incorporated into 'Timestamp'\n",
        "selected_columns = selected_columns.drop('time', axis=1)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(selected_columns.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UijIUvut61rE",
        "outputId": "71358a9d-11da-4770-c811-9083e01da5e9"
      },
      "outputs": [],
      "source": [
        "selected_columns.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzKMduvH6_Ws"
      },
      "source": [
        "**Regex and query patterns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El2tVh1G64oy",
        "outputId": "47e274d8-c121-463f-9fb2-94ea42470cdf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Define the regular expressions\n",
        "regex_patterns = {\n",
        "  \"service_specific_dns\": r\"^_ldap\\._tcp\\.dc\\._msdcs\\.[A-Z]+\\.[A-Z]+$\",\n",
        "  \"uuid_based_service_specific_dns\": r\"^_ldap\\._tcp\\.[0-9a-fA-F-]{36}\\.domains\\._msdcs\\.[A-Z]+\\.[A-Z]+$\",\n",
        "  \"standard_hostname_domain\": r\"^[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",\n",
        "  \"complex_subdomain_structure\": r\"^[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",\n",
        "  \"standard_hostname_subdomain\": r\"^[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",\n",
        "  \"simple_domain\": r\"^[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",  # Added to match simple domains like \"amazon.com\"\n",
        "  \"single_label_domain\": r\"^[a-zA-Z0-9-]+$\",  # Added to match single label domains like \".\"\n",
        "  \"extended_subdomain_structure\": r\"^[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",  # Extended subdomain structure\n",
        "  \"another_extended_subdomain_structure\": r\"^[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",  # Another extended subdomain structure\n",
        "  \"ip_based_subdomain\": r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",  # IP-based subdomain\n",
        "  \"complex_ip_based_subdomain\": r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",  # Complex IP-based subdomain\n",
        "  \"subdomain_with_underscore\": r\"^[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}$\",  # Subdomain with underscore\n",
        "  \"complex_subdomain_with_underscore\": r\"^[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+\\.[a-zA-Z]{2,}$\"  # Complex subdomain with underscore\n",
        "}\n",
        "\n",
        "\n",
        "# Extract query names\n",
        "query_names = selected_columns['Query'].tolist()\n",
        "\n",
        "# Function to match query names to regex patterns\n",
        "def match_query_names(query_names, regex_patterns):\n",
        "  matches = {}\n",
        "  for name in query_names:\n",
        "      for pattern_name, pattern in regex_patterns.items():\n",
        "          if re.match(pattern, name):\n",
        "              matches[name] = pattern_name\n",
        "              break\n",
        "  return matches\n",
        "\n",
        "# Match the query names\n",
        "matched_queries = match_query_names(query_names, regex_patterns)\n",
        "\n",
        "# Print the results\n",
        "for query, pattern_name in matched_queries.items():\n",
        "  print(f\"Query: {query} matches pattern: {pattern_name}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUbvTFnA7Q67"
      },
      "source": [
        "**IP Address and Time stamp duration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "0VFh9GCu7b8V",
        "outputId": "a6a64469-1716-461c-a3c4-0a414fde6061"
      },
      "outputs": [],
      "source": [
        "\"\"\"import pandas as pd\n",
        "\n",
        "# Clean up the 'IP Address' column by removing parentheses\n",
        "# str.replace(r'[()]', '', regex=True) removes both opening and closing parentheses in one go\n",
        "selected_columns['IP Address'] = selected_columns['IP Address'].str.replace(r'[()]', '', regex=True)\n",
        "\n",
        "# Set the 'Timestamp' column as the index and ensure it's in datetime format\n",
        "selected_columns['Timestamp'] = pd.to_datetime(selected_columns['Timestamp'])\n",
        "#selected_columns.set_index('Timestamp', inplace=True)\n",
        "\n",
        "# Get unique IP addresses in the DataFrame\n",
        "unique_ip_addresses = selected_columns['IP Address'].unique()\n",
        "\n",
        "# Iterate through each unique IP address\n",
        "for ip_address in unique_ip_addresses:\n",
        "  # Filter the DataFrame by the current IP address\n",
        "  filtered_df = selected_columns[selected_columns['IP Address'] == ip_address]\n",
        "\n",
        "  # Ensure the DataFrame is sorted by index (timestamp) before resampling\n",
        "  filtered_df = filtered_df.sort_index()\n",
        "\n",
        "  # Resample the data to the desired time intervals and count the number of queries\n",
        "  resampled_30min = filtered_df.resample('30T').size()\n",
        "  resampled_1hour = filtered_df.resample('1H').size()\n",
        "  resampled_1day = filtered_df.resample('1D').size()\n",
        "  resampled_3days = filtered_df.resample('3D').size()\n",
        "\n",
        "  # Combine the results into a DataFrame\n",
        "  results = pd.DataFrame({\n",
        "      '30min': resampled_30min,\n",
        "      '1hour': resampled_1hour,\n",
        "      '1day': resampled_1day,\n",
        "      '3days': resampled_3days\n",
        "  }).fillna(0).astype(int)\n",
        "\n",
        "  # Print the results for the current IP address\n",
        "  print(f\"\\nResampled results for IP address {ip_address}:\")\n",
        "  print(results)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pEKqWPa7ogd"
      },
      "source": [
        "**Using regex extract domain name**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "anANRKTP7sMn",
        "outputId": "d0bd3e08-452f-42c7-a152-11be384fade4"
      },
      "outputs": [],
      "source": [
        "# Define a regex pattern to extract the domain name\n",
        "# This pattern captures the domain name and its extension\n",
        "domain_pattern = r'^(?:https?://)?(?:www\\.)?([^/]+)'\n",
        "\n",
        "# Extract the domain name from the 'Query' column\n",
        "selected_columns['domain'] = selected_columns['Query'].str.extract(domain_pattern)\n",
        "\n",
        "# Print the DataFrame to see the new 'domain' column\n",
        "selected_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pu-cVQ779oS"
      },
      "source": [
        "**Read Domain_label.txt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0A9e6BzT8BwX",
        "outputId": "c786ca1a-373f-4804-cd59-3976a8be7f2a"
      },
      "outputs": [],
      "source": [
        "domain_data=pd.read_csv(\"domain_labels.txt\",sep=\"\\t\")\n",
        "domain_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwBiJ3-98Klc"
      },
      "source": [
        "**Read data from each column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NY8IVBy8Gwv",
        "outputId": "f1b30d95-2d00-4d3c-c716-835998780e9b"
      },
      "outputs": [],
      "source": [
        "# Read data from the text file\n",
        "with open('domain_labels.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "data = []\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "    parts = line.split(',') + [\"\"] * (4 - len(line.split(',')))\n",
        "    data.append(parts)\n",
        "column1, column2, column3, column4 = zip(*data)\n",
        "print(\"Column 1:\", list(column1))\n",
        "print(\"Column 2:\", list(column2))\n",
        "print(\"Column 3:\", list(column3))\n",
        "print(\"Column 4:\", list(column4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O0IN75-8Vs5"
      },
      "source": [
        "**Display text file data as dataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "osEy0OYp8R7X",
        "outputId": "c9d08d7a-ad42-474d-fd2d-1f9f3422c32d"
      },
      "outputs": [],
      "source": [
        "data_1=pd.DataFrame({\"domain_name\":list(column1),\"categorized\":list(column2),\"category\":list(column3),\"risk\":list(column4)})#.map({\"False\":0,\"True\":1,\"Benign\":0,\"Low\":1})\n",
        "data_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlwSqJUk8hp8"
      },
      "source": [
        "**Map and replace values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "PUBp3S4a8hKV",
        "outputId": "a16b1030-7cd9-4bbb-eff2-efd6187ec899"
      },
      "outputs": [],
      "source": [
        "print(data_1[\"categorized\"].unique())\n",
        "data_1[\"categorized\"]=data_1[\"categorized\"].replace({\"False\":0,\"True\":1})\n",
        "\n",
        "print(data_1[\"category\"].unique())\n",
        "data_1[\"category\"]=data_1[\"category\"].replace({\"Benign\":1})\n",
        "\n",
        "print(data_1[\"risk\"].unique())\n",
        "data_1[\"risk\"]=data_1[\"risk\"].replace({\"Low\":0})\n",
        "\n",
        "data_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zoE_wJ38xYM"
      },
      "source": [
        "**Final Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "xyDgtppU8xCy",
        "outputId": "99263dc0-bdc1-40f8-8924-a75f6764a660"
      },
      "outputs": [],
      "source": [
        "selected_columns.join(data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0t25dvp89Ua",
        "outputId": "196b1159-f3a9-4986-aeeb-76220f37e62c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Clean up the 'IP Address' column by removing parentheses\n",
        "# str.replace(r'[()]', '', regex=True) removes both opening and closing parentheses in one go\n",
        "selected_columns['IP Address'] = selected_columns['IP Address'].str.replace(r'[()]', '', regex=True)\n",
        "\n",
        "# Set the 'Timestamp' column as the index and ensure it's in datetime format\n",
        "selected_columns['Timestamp'] = pd.to_datetime(selected_columns['Timestamp'])\n",
        "selected_columns.set_index('Timestamp', inplace=True)\n",
        "\n",
        "# Get unique IP addresses in the DataFrame\n",
        "unique_ip_addresses = selected_columns['IP Address'].unique()\n",
        "\n",
        "# Iterate through each unique IP address\n",
        "for ip_address in unique_ip_addresses:\n",
        "  # Filter the DataFrame by the current IP address\n",
        "  filtered_df = selected_columns[selected_columns['IP Address'] == ip_address]\n",
        "\n",
        "  # Ensure the DataFrame is sorted by index (timestamp) before resampling\n",
        "  filtered_df = filtered_df.sort_index()\n",
        "\n",
        "  # Resample the data to the desired time intervals and count the number of queries\n",
        "  resampled_30min = filtered_df.resample('30T').size()\n",
        "  resampled_1hour = filtered_df.resample('1H').size()\n",
        "  resampled_1day = filtered_df.resample('1D').size()\n",
        "  resampled_3days = filtered_df.resample('3D').size()\n",
        "\n",
        "  # Combine the results into a DataFrame\n",
        "  results = pd.DataFrame({\n",
        "      '30min': resampled_30min,\n",
        "      '1hour': resampled_1hour,\n",
        "      '1day': resampled_1day,\n",
        "      '3days': resampled_3days\n",
        "  }).fillna(0).astype(int)\n",
        "\n",
        "  # Print the results for the current IP address\n",
        "  print(f\"\\nResampled results for IP address {ip_address}:\")\n",
        "  print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFz3lHVTCKH8",
        "outputId": "8dbb500f-0c81-4f17-d7e2-68f07abdbcf2"
      },
      "outputs": [],
      "source": [
        "selected_columns.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq_CqjZHA4cc"
      },
      "source": [
        "**LSTM model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Br2Kjj6CpQm"
      },
      "source": [
        "**1. Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPr7GOOn-0Dm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxkXvJxtCzwZ"
      },
      "source": [
        "**2. Load data feature column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT0lOeOhCuzX"
      },
      "outputs": [],
      "source": [
        "# Load the DataFrame (assuming you have the data in a CSV file)\n",
        "\n",
        "\n",
        "# Select the relevant columns\n",
        "selected_columns = selected_columns[['Client', 'Client ID', 'Query ID', 'Query', 'Class', 'Record Type', 'Flags', 'IP Address', 'domain']]\n",
        "\n",
        "# For this example, we'll use 'Query ID' as the target to predict\n",
        "# You can choose any other numerical column if needed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCcl4XVCC_d5"
      },
      "source": [
        "**3. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_m6-TdMDA8h"
      },
      "outputs": [],
      "source": [
        "# Check and remove non-numeric values from 'Query ID'\n",
        "selected_columns['Query ID'] = pd.to_numeric(selected_columns['Query ID'], errors='coerce')\n",
        "selected_columns = selected_columns.dropna(subset=['Query ID'])\n",
        "\n",
        "# Scale the 'Query ID' column (or any other numerical column you choose to predict)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(selected_columns['Query ID'].values.reshape(-1, 1))\n",
        "\n",
        "# Convert the DataFrame to a format suitable for LSTM\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        X.append(data[i:(i + time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Define the number of previous steps to consider for prediction (e.g., 60)\n",
        "time_step = 60\n",
        "\n",
        "# Create the dataset for training\n",
        "X, y = create_dataset(scaled_data, time_step)\n",
        "\n",
        "# Reshape the input to be [samples, time steps, features] as required for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP0Kf7yBDifa"
      },
      "source": [
        "**4. Build the LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dxvyKciDBlJ",
        "outputId": "656be5b6-acb0-4beb-cb30-a1eee8b219a3"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(time_step, 1)))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dense(units=25))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9_y4OnBDmoK"
      },
      "source": [
        "**5. Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBq6cr-SDm8a",
        "outputId": "cc267d40-5400-4bc5-cde3-da60beca4175"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trF115rzDwUC"
      },
      "source": [
        "**6. Make Predictions and Visualize the Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "GAymPp3HDwpz",
        "outputId": "29fac512-3edb-4efd-a4a0-f122cd93a4ef"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# Inverse transform to get actual values\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
        "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.plot(range(len(y_train_actual)), y_train_actual, color='blue', label='Training data')\n",
        "plt.plot(range(len(y_train_actual), len(y_train_actual) + len(y_test_actual)), y_test_actual, color='green', label='Testing data')\n",
        "plt.plot(range(len(y_train_actual)), train_predict, color='red', label='Training prediction')\n",
        "plt.plot(range(len(y_train_actual), len(y_train_actual) + len(y_test_actual)), test_predict, color='orange', label='Testing prediction')\n",
        "plt.title('Query ID Prediction')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Query ID')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSb3sLsNLo8C"
      },
      "source": [
        "**7. Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP_GBz3CLJKq",
        "outputId": "bcc44b3e-c66c-457a-b98a-0aa05b236431"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Calculate metrics\n",
        "mse_train = mean_squared_error(y_train_actual, train_predict)\n",
        "mse_test = mean_squared_error(y_test_actual, test_predict)\n",
        "\n",
        "mae_train = mean_absolute_error(y_train_actual, train_predict)\n",
        "mae_test = mean_absolute_error(y_test_actual, test_predict)\n",
        "\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "\n",
        "r2_train = r2_score(y_train_actual, train_predict)\n",
        "r2_test = r2_score(y_test_actual, test_predict)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Training : \")\n",
        "print(f\"Train MSE: {mse_train}\")\n",
        "print(f\"Train MAE: {mae_train}\")\n",
        "print(f\"Train RMSE: {rmse_train}\")\n",
        "print(f\"Train R^2: {r2_train}\")\n",
        "print(\"\\nTesting : \")\n",
        "print(f\"Test MSE: {mse_test}\")\n",
        "print(f\"Test MAE: {mae_test}\")\n",
        "print(f\"Test RMSE: {rmse_test}\")\n",
        "print(f\"Test R^2: {r2_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRn-7G3XLu7K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
